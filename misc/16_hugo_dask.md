
```text
## Upcoming Events
Join our Meetup group for more events!
https://www.meetup.com/data-umbrella

# Hugo Bowne-Anderson and James Bourbeau:  Data Science and Machine Learning at Scale

## Key Links
- Transcript:  https://github.com/data-umbrella/event-transcripts/blob/main/2020/16-hugo-james-dask.md
- Meetup Event:  https://www.meetup.com/data-umbrella/events/273593514/
- Video:   https://youtu.be/MHAjCcBfT_A
- Jupyter notebook:  https://github.com/coiled/data-science-at-scale/tree/master/notebooks/data-umbrella-2020-10-27
- GitHub repo:  https://github.com/coiled/data-science-at-scale


## Agenda
00:00:00 Reshama introduces Data Umbrella
00:04:15 Hugo introduces the talk
00:09:53 James describes Dask APIs
00:11:20 Dask Schedulers and Workers
00:15:15 Demo: Dask in action
00:21:18 Tutorial goals and general workflow
00:23:28 Optional: Spin up a cluster on Coiled
00:26:51 Why scaling easily on the cloud is important? 
00:28:29 Loading of large datasets
00:32:44 Dask DataFrames
00:36:42 Getting started with Dask DataFrames
00:40:38 Computations with Dask DataFrames
00:43:07 Q: How to use Dask for reinforcement learning?
00:44:19 Use of Dask scheduler for different use cases
00:46:50 Parallel and Distributed Machine Learning
00:49:05 Scikit-learn in 5 minutes
00:56:58 Joblib for local parallel processing
00:58:09 Q: Does Dask have a SQL and Query optimizer?
00:59:22 Multi-machine parallel processing with Dask
01:04:15 Q: Performance gains Dask vs. Joblib
01:08:28 Closing thoughts 
 
## Event
In this tutorial, you'll learn everything you wanted to know about scaling your data science work to larger datasets and larger models, while staying in the comfort of the PyData ecosystem (numpy, pandas, scikit-learn, Jupyter notebooks).

You'll come away knowing

* How to reason about when you need to scale your data and machine learning work and when to not;
* How to leverage distribute computation on your local workstation (such as your laptop) to analyze larger datasets and build larger, more complex models;
* How to harness the power of clusters to support larger-than-memory computation, all from the comfort of your own laptop;
* How to do all of this while writing code similar to the numpy, pandas, and/or sckit-learn code you already write.

## About the Speakers

Hugo Bowne-Anderson is Head of Data Science Evangelism and Marketing at Coiled, a company that makes it simple for organizations to scale their data science seamlessly. He has extensive experience as a data scientist, educator, evangelist, content marketer, and data strategy consultant at DataCamp, the online education platform for all things data. He also has experience teaching basic to advanced data science topics at institutions such as Yale University and Cold Spring Harbor Laboratory, conferences such as SciPy, PyCon, and ODSC and with organizations such as Data Carpentry. He has developed over 30 courses on the DataCamp platform, impacting over 500,000 learners worldwide through his own courses. He also created the weekly data industry podcast DataFramed, which he hosted and produced for 2 years. He is committed to spreading data skills, access to data science tooling, and open source software, both for individuals and the enterprise. He has taught workshops & tutorials at SciPy, PyCon, ODSC, with the Carpentries, and has taught online many times over the years, including developing both product and content for online data science curriculum at DataCamp.

James Bourbeau is a Software Engineer at Coiled where he focuses on building tools for scalable computing. He is an active member of the PyData ecosystem where he maintains several open source projects including Dask and Distributed. Previously James worked at Quansight where he helped clients leverage open source scientific Python libraries for data science applications.

Twitter:https://twitter.com/hugobowne
GitHub:https://github.com/hugobowne
LinkedIn: https://www.linkedin.com/in/hugo-bowne-anderson-045939a5/

```
